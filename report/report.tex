\documentclass[a4paper,UKenglish]{lipics-v2016}
% This template is based on the template for producing LIPIcs articles.
% See lipics-manual.pdf for further information.
% https://www.dagstuhl.de/en/publications/lipics/instructions-for-authors/
% for section-numbered lemmas etc., use "numberwithinsect"

% we do not need the copyright line or the DOI
\renewcommand{\copyrightline}{}
\DOIPrefix{}

\bibliographystyle{plainurl}% the recommended bibstyle

% Author macros::begin %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Advanced Type-Based Analysis: Summary of Selected Papers}

%% Add all author names here
\author[1]{Nikita Ziuzin}
\author[2]{Joachim Bard}
\author[3]{Hizbullah Abdul Aziz}
% List email addresses in the same order as the authors
\affil[1]{\texttt{nzyuzin93@gmail.com}}
\affil[2]{\texttt{s9jobard@stud.uni-saarland.de}}
\affil[3]{\texttt{s8hijabb@stud.uni-saarland.de}}

\begin{document}

\maketitle


\section{Introduction}
  
  Many programming languages have some sort of type system that enforces a
  certain notion of correctness from a program.  For example, a function that
  adds two numbers, when defined correctly, should only works on numbers and
  nothing else (which are reflected on the type of its arguments).  A
  typechecker ensures that a program is well-typed, that is, everything has a
  well-defined type, by statically checking the type of every part of a program
  (usually) during compile time.  In this particular example, trying to call
  the addition function on a number and a boolean valua should make the
  typechecker rejects the program as not well-typed.  

  However, well-typed programs can still go wrong.  Standard type systems found
  in mainstream programming language such as C, Java, or even the more advanced
  ones in ML or Haskell can't prevent some bad runtime behaviors such as
  division by zero.  Thus there have been some research on extending types and
  type systems to become more expressive.  In particular, there is a notion of
  Dependent Types, which are types that depend on some values.  Starting with
  statically checking array bound as a motivating example, Dependent Types
  have spawned many subsequent researches, two of which will be presented in
  this report.

  In this summary, we will begin with the high-level summary Dependent Types
  itself~\cite{Xi:1998:EAB}.  We will then proceed with a brief explanation of
  Liquid Types~\cite{Rondon:2008:LT}, which is types \emph{refined} with
  predicates that builds on the ideas of Dependent Types.  In particular,
  Liquid Types make it possible to reduce the number of annotation needed while
  at the same time retains the benefit of Dependent Types.  Finally, we
  summarizes the approach taken to bring Liquid Types under lazy evaluation
  settings~\cite{Vazou:ICFP:2014}.

  % This is from of the template
  In high-level terms
  \begin{itemize}
    \item introduce the topic

    \item explain why it is relevant/related to the course (i.e. how is it related
    to static analysis)

    \item explain why the topic is important (e.g. where and how can it be used)

    \item introduce your chosen papers and briefly explain how they are related
    to the topic
  \end{itemize}

\section{Summary of Papers}

  \subsection{Paper 1}
  \subsection{Paper 2}
  \subsection{Refinement Types For Haskell}

    \subsubsection{Lazy Evaluation}

      Some programming languages, most notably Haskell, use a different
      evaluation strategy called lazy evaluation.  Intuitively, lazy evaluation
      means that computations is only performed if the results of those
      computations are needed.  For example, if a program specifies that the
      result of \texttt{div 10 5} be printed on screen, then the this
      computation i.e. divide 10 by 5 will be computed.  Conversely, if the
      result of \texttt{div 10 5} is never needed, then it will never return a
      value.  

      It turns out that classical approach on refinement types is unsound under
      lazy evaluation, in the sense that the typechecker will admit some bad
      behaviours.  Consider the following example.
      \begin{verbatim}
        type Pos = { v:Int | v >  0 }
        type Nat = { v:Int | v >= 0 }

        div :: n:Nat -> d:Pos -> { v:Nat | v < n } 
        (+) :: x:Int -> y:Int -> { v:Int | v = x + y }
        diverge :: Int -> { v:Nat | false } 

        explode :: Int -> Int
        explode x = let n = diverge 1 in 
                    let y = 0 in 
                    div x y
      \end{verbatim}

      When checking for the type of \texttt{y}, the typechecker will generate
      the constraint
      $$\mathtt{false}\wedge(y=0)\implies(v=0)\implies(v>0)$$
      which any SMT solver will accept since we have falsity in the antecedent.
      Note that the \texttt{false} part in the constraint comes from
      \texttt{diverge}, which essentially states that this function diverges
      i.e. will not return any value.

      This constraint is of course sound under eager evaluation, since we will
      never get into calling \texttt{div} with the second argument equals to
      zero i.e. division by zero.  Under lazy evaluation however, since
      \texttt{n} is not needed in the computation of the result of
      \texttt{explode}, the computation will jump straight into evaluating
      \texttt{div} thus resulting in division by zero.  Recall that the type of
      \texttt{div} should prevent this since it requires its second argument to
      have type \texttt{Pos}, a positive integer, which proves the unsoundness
      of the previous approach.

    \subsubsection{Solution}
      
      To restore soundness, the main idea is to label binders as potentially
      diverging and omit those in the typing constraint.  Returning to the
      previous example, by omitting \texttt{diverge} in the constraint, we have
      $$\mathtt{true}\wedge(y=0)\implies(v=0)\implies(v>0)$$
      which is now an invalid constraint and thus the typechecker will reject
      this as not well-typed.

      One way to implement this is to have a \emph{stratified} type system
      consisting of types which may diverge and those which may not.
      \begin{itemize}
        \item Initially, every binders have types which may diverge.  This is
          sound but very imprecise since now there is no constraint at all.
        \item Then termination analysis is used to determine which binders
          actually terminate, thus getting some constraints back.
      \end{itemize}

      Now it should be clear that the accuracy of this approach depends on the
      termination analysis.  Loosely speaking, there are three main points of
      it.
      \begin{itemize}
        \item As with previous approaches, the refinements itself must be
          restricted into some sort of decidable logic, because otherwise
          typechecking would be undecidable.  Here refinements are drawn from
          QF-EUFLIA, the decidable logic of equality, uninterpreted
          functions and linear arithmetic.
        \item To prove termination of inductively defined functions i.e.
          recursive functions, it employs some default size measures and check
          whether those measures decrease on each (recursive) function call.
          This approach is of course not unlike one found in other programming
          languages such as Coq. Using these default measures, termination can
          be proven automatically.
        \item If the automatic termination analysis fails, then the size
          measure must be explicitly specified by the user.
      \end{itemize}

    \subsection{Implementation and Result}
      
      LIQUIDHASKELL, a Haskell extension with refinement types succesfully
      brings refinement typechecking under lazy evaluation.  The termination
      analysis used in LIQUIDHASKELL is usable since it only requires about 1
      line of code of explicit size measure per 100 line of code, thus
      retaining the advantage of previous approach while maintaining soundness
      under lazy evaluation.

\section{Context and Connection (feel free to change the section names)}

  As briefly mentioned in~\ref{section:Introduction}, Dependent Types and its
  subsequent improvements are extensions to the standard type systems discussed
  in the class.  These extensions make the type system more expressive and thus
  enable it to prove (and enforce) more properties.

  From Dependent Types, Liquid Types takes the idea of refinement types further
  and enable automatic inference of types thus reducing the need for manual
  type annotations.  Lastly, LIQUIDHASKELL fixed the soundness of Liquid Types
  under lazy evaluation while retains its advantage of automatic type
  inference.

  % This is from the template
  Now that the content of the papers has been explained in more detail,
  this section should
  \begin{itemize}
    \item put the papers into context (as seen in the class). E.g. how do the
    ideas presented in the paper related to ideas seen in class; are the techniques
    an extension; if they are completely different, explain how (and perhaps why), etc.

    \item explain the connections and/or differences between the papers.
      E.g. if they present different approaches, how do these compare, what are the pros/cons?
      If the techniques build on each other, how are they connected?
      If they are part of a larger system, how do they complement each other?
      Etc.

  \end{itemize}

\section{Conclusion}

  What is the 'take-home-message'?

%%
%% Bibliography
%%

%% Either use bibtex (recommended),

\bibliography{main}

%% .. or use the thebibliography environment explicitely



\end{document}
